function metrics_τ(pars_m3, Z0_bp, q, μ_w, λ)
    samples = τ_dist_from_w(pars_m3, Z0_bp, q, μ_w, λ)
    return mean(samples), var(samples)
end

function moments_gengamma(n, a, d, p)
    # if (gamma((d + n) / p) == 0) || !isfinite(gamma(d / p)) || (gamma(d / p) == 0)
    # if isfinite(gamma(d / p))
    if a > 0 && d > 0 && p > 0
        return exp(n * log(a) + (loggamma((d + n) / p) - loggamma(d / p)))
    else
        return Inf
    end
end

function get_ode_β(R₀, k, δ, πv, c; S0 = 8e7)
    """
    Calculate the infection rate β from the other parameters.
    """
    return δ * c * R₀ / (πv * S0)
end

function get_bp_β(R₀, k, δ, πv, c; S0 = 8e7)
    """
    Calculate the infection rate β from the other parameters.
    """
    return δ * c * R₀ / πv
end

function get_gg_pars(pars, Z0_bp; S0 = 8e7)
    """
    Calculate the parameters of the GG distribution for the within-host model.
    """
    R₀, k, δ, πv, c = pars
    β_bp = get_bp_β(R₀, k, δ, πv, c)

    # Calculate omega matrix and artefacts from that.
    Ω = [
        -k k 0
        0 -δ πv
        β_bp 0 -c
    ]

    λ, u_norm, v_norm = calculate_BP_contributions(Ω)

    # Calc expected value of W
    μ_w = dot(Z0_bp, u_norm)

    # Get the first 5 moments
    num_moments = 5
    lifetimes = (k, δ + πv, c + β_bp)

    αs = Dict(1 => Dict([1, 2] => k))
    βs = Dict(2 => Dict([2, 2, 3] => πv), 3 => Dict([3, 1, 3] => β_bp))

    moments = calculate_moments_generic(Ω, αs, βs, lifetimes)

    q = calculate_extinction_prob(pars)

    # Using the moments, calculate the parameters of the GG distribution and sample
    # pars_m3, _ = minimise_loss(moments, q)
    pars_m3 = minimise_loss(moments, q)

    return μ_w, λ, pars_m3, q
end

function read_data()
    """
    Reads in the data generated by the `generate_data` function and returns it as a dictionary.
    """
    df_input = CSV.read(data_dir("tcl_nn/gg_fitting_data.csv"), DataFrame)
    df_output = CSV.read(data_dir("tcl_nn/gg_fitting_data_output.csv"), DataFrame)
    df_measures = CSV.read(data_dir("tcl_nn/gg_fitting_data_measures.csv"), DataFrame)
    input = Matrix(df_input)
    output = Matrix(df_output)
    data_measures = Matrix(df_measures)

    return Dict("input" => input, "output" => output, "data_measures" => data_measures)
end

function standardise_data(data)
    """
    standardises the data for the data to the neural network. This is a standard normal normalisation
    where we subtract the mean and divide by the standard deviation.
    """
    mean_scaling = mean(data, dims = 1)
    std_scaling = std(data, dims = 1)
    data_norm = (data .- mean_scaling) ./ std_scaling
    return data_norm, mean_scaling, std_scaling

    # median_scaling = median(data, dims = 1)
    # iqr_scaling = zeros(size(median_scaling))
    # data_norm = deepcopy(data)
    # for (i, col) in enumerate(eachcol(data_norm))
    #     iqr_scaling[i] = quantile(col, 0.75) - quantile(col, 0.25)
    #     data_norm[:, i] = (data_norm[:, i] .- median_scaling[i]) ./ iqr_scaling[i]
    # end

    # return data_norm, median_scaling, iqr_scaling
end

function unstandardise_data(data_norm, mean_scaling, std_scaling)
    """
    Inverts what is done by the `normalise_data` function.
    """
    m, n = size(data_norm)
    m_mean_scaling, n_mean_scaling = size(mean_scaling)
    @assert n == n_mean_scaling    # check that the data is in  the correct format
    data = data_norm .* std_scaling .+ mean_scaling
    return data
end

# function unstandardise_data(data_norm, median_scaling, iqr_scaling)
#     """
#     Inverts what is done by the `normalise_data` function.
#     """
#     m, n = size(data_norm)
#     m_median_scaling, n_median_scaling = size(median_scaling)
#     @assert n == n_median_scaling    # check that the data is in  the correct format
#     data = data_norm .* iqr_scaling .+ median_scaling
#     return data
# end

function minmax_scaling(data)
    """
    Scales the data to be between 0 and 1.
    """
    min_scaling = minimum(data, dims = 1)
    max_scaling = maximum(data, dims = 1)
    m, n = size(data)
    @assert m >= n   # check that the data is in  the correct format
    data_norm = (data .- min_scaling) ./ (max_scaling - min_scaling)

    return data_norm, min_scaling, max_scaling
end
